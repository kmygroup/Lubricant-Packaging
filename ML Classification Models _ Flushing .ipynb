{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1EHmFauO4QoE2-9fD3TakhdH3Hu3fUCT7","timestamp":1743712933164}],"authorship_tag":"ABX9TyMMjexWH4IgHYhsmVGxo7WR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Machine Learning Classification Models for Multi-Product Pipeline Lubricant Oil Flush Categorization Into Pass or Failed Flush Scenarios"],"metadata":{"id":"xLrRzog7J9bb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"bP_rY0RfJ6jM"},"outputs":[],"source":["#Import Libraries\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import cross_val_score, cross_validate\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from xgboost import XGBClassifier\n","from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.inspection import permutation_importance\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras import Sequential\n","from sklearn.model_selection import StratifiedKFold, KFold\n","from xgboost import XGBClassifier\n","import xgboost as xgb\n","from xgboost import cv\n","from xgboost import XGBClassifier, plot_importance\n","\n","# data upload\n","\n","link =\"\"\n","data = pd.read_excel(link)\n","\n","#data preview\n","data.columns\n","\n","#check for missing data\n","data.isnull().sum()\n","\n","#label encoding\n","for i in range(len(data['Prod. Line'])):\n","  if data.loc[i,'Prod. Line'] == \"DF\":\n","    data.loc[i,'Prod. Line'] = 1\n","  elif data.loc[i,'Prod. Line'] == \"1\":\n","    data.loc[i,'Prod. Line'] = 2\n","  elif data.loc[i,'Prod. Line'] == \"2\":\n","    data.loc[i,'Prod. Line'] = 3\n","  elif data.loc[i,'Prod. Line'] == \"3\":\n","    data.loc[i,'Prod. Line'] = 4\n","  elif data.loc[i,'Prod. Line'] == \"4\":\n","    data.loc[i,'Prod. Line'] = 5\n","\n","#print data after preprocessing\n","data = pd.get_dummies(data, columns=['System Type'], prefix='System Type')\n","data = data.dropna(subset=['Source \\nTank'], axis=0)\n","\n","#Data categorization into family types\n","data1 = data[data['Compatibility'].str.contains('AE', na = False)] #\n","data1\n","\n","#X and y data for training\n","X = data1[['Documented \\nFlush','Flush KV40','Flush KV100','Avg Ambient Temp (degF) ','Prod. Line','System Type_2.0', 'System Type_3.0']]\n","X = X.rename(columns = {\"Documented \\nFlush\": \"Documented Flush\",\"Prod. Line\":\"Drum_Fill\"})\n","X = X.astype({'Drum_Fill':'int'})\n","Y = data1['Failed']\n","\n","#check for null\n","X.isna().sum()\n","\n","#data transformation\n","sc = MinMaxScaler(feature_range=(0,1))\n","scaled_data = sc.fit_transform(X.iloc[:,:-2])\n","data_to_scale = pd.DataFrame(scaled_data, columns=X.iloc[:,:-2].columns)\n","frames = [data_to_scale, X.iloc[:,-2:]]\n","\n","#data splitting for Random Forest (RF)\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","RF = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42)\n","\n","#Check cross validataion\n","clf_RF = cross_val_score(RF, X_train, y_train, cv=10)\n","clf_RF.mean()\n","\n","#data cross validation through stratified k-fold method\n","skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","#feature importances\n","for fold, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n","    x_train_fold, x_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n","    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n","    RF = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=42)\n","    model = RF.fit(x_train_fold, y_train_fold)\n","    fold_ = fold + 1\n","    tite = \"Feature Importance for Fold \" + str(fold_)\n","    scorer = make_scorer(mean_squared_error, greater_is_better=False)\n","    perm = permutation_importance(model, x_test_fold, y_test_fold, n_repeats=5, random_state=42, scoring=scorer)\n","    importances = perm.importances_mean\n","    idxx = np.argsort(importances)\n","    plt.barh(range(len(idxx)),importances[idxx])\n","    plt.yticks(range(len(idxx)), [ feature for feature in X_train.columns])\n","    plt.title(tite)\n","    filenaem = '/content/drive/MyDrive/' + 'fold_' + str(fold_) + '.png'\n","    plt.savefig(filenaem, dpi=1400, bbox_inches=\"tight\")\n","    plt.show()\n","\n","\n","#mode predictions\n","model = RF.fit(X_train, y_train)\n","Y1P_HH = model.predict(X_train)\n","Y2P_HH = model.predict(X_test)\n","\n","#print model metrics\n","print(\"Accuracy Score (training) = \", accuracy_score(y_train, Y1P_HH), \"\\t||  R2_score (testing) = \", accuracy_score(y_test, Y2P_HH))\n","\n","scorer = make_scorer(mean_squared_error, greater_is_better=False)\n","perm = permutation_importance(model, X_test, y_test, n_repeats=5, random_state=42, scoring=scorer)\n","importances = perm.importances_mean\n","idxx = np.argsort(importances)\n","\n","\n","#confusion matrix plots\n","plt.figure(figsize=(10,8), dpi=2000)\n","plt.barh(range(len(idxx)),importances[idxx])\n","plt.title(\"Random Forest: Feature Importance\",fontsize=40)\n","plt.xlabel(\"Importance\",fontsize=35)\n","plt.xticks(fontsize=35)\n","plt.yticks(range(len(idxx)), [ feature for feature in X.columns])\n","plt.yticks(fontsize=35)\n","#plt.savefig(\"c://downloads\", dpi=1400, bbox_inches=\"tight\")\n","plt.show()\n","\n","\n","#******************************************#\n","#XGBoost\n","#******************************************#\n","#data matrix\n","data_dmatrix = xgb.DMatrix(data=X,label=Y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# Initialize the model with specified hyperparameters\n","model = XGBClassifier(\n","    alpha=10,\n","    base_score=0.5,\n","    booster='gbtree',\n","    colsample_bylevel=1,\n","    colsample_bynode=1,\n","    colsample_bytree=1,\n","    gamma=0,\n","    learning_rate=1.0,\n","    max_delta_step=0,\n","    max_depth=4,\n","    min_child_weight=1,\n","    n_estimators=100,\n","    n_jobs=1,\n","    objective='binary:logistic',\n","    random_state=42,\n","    reg_alpha=0,\n","    reg_lambda=1,\n","    scale_pos_weight=1,\n","    subsample=1,\n","    verbosity=1\n",")\n","\n","# Train the model\n","model.fit(X_train, y_train)\n","\n","\n","y_pred = model.predict(X_test)\n","\n","#train parameters\n","params = {\n","    \"alpha\":10,\n","    \"base_score\":0.5,\n","    \"booster\":\"gbtree\",\n","    \"colsample_bylevel\":1,\n","    \"colsample_bynode\":1,\n","    \"colsample_bytree\":1,\n","    \"gamma\":0,\n","    \"learning_rate\":1.0,\n","    \"max_delta_step\":0,\n","    \"max_depth\":4,\n","    \"min_child_weight\":1,\n","    \"n_estimators\":100,\n","    \"n_jobs\":1,\n","    \"objective\":'binary:logistic',\n","    \"random_state\":42,\n","    \"reg_alpha\":0,\n","    \"reg_lambda\":1,\n","    \"scale_pos_weight\":1,\n","    \"subsample\":1,\n","    \"verbosity\":1\n","}\n","\n","\n","xgb_cv = cv(dtrain=data_dmatrix, params=params, nfold=10,\n","                    num_boost_round=50, early_stopping_rounds=10, metrics=\"auc\", as_pandas=True, seed=123)\n","\n","\n","\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","# Print evaluation metrics\n","print(f'Accuracy: {accuracy:.2f}')\n","print(f'Precision: {precision:.2f}')\n","print(f'Recall: {recall:.2f}')\n","print(f'F1 Score: {f1:.2f}')\n","\n","\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fail', 'Pass'], yticklabels=['Fail', 'Pass'])\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","\n","from xgboost import XGBClassifier, plot_importance\n","\n","plt.figure(figsize=(10, 6))\n","plot_importance(model, max_num_features=10)\n","plt.title('Feature Importance')\n","plt.show()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"E2k6j9MvKOZ7"},"execution_count":null,"outputs":[]}]}